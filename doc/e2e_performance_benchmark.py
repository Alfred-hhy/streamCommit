"""
ç«¯åˆ°ç«¯æ€§èƒ½åŸºå‡†æµ‹è¯• / End-to-End Performance Benchmark
=======================================================

æµ‹è¯•å®Œæ•´çš„ VDS Scheme C+ å·¥ä½œæµæ€§èƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. æ‰¹æ¬¡åˆ›å»º (DO)
2. æ•°æ®æ¶ˆè´¹è€…æŸ¥è¯¢ (DC)
3. å®¡è®¡å‘˜å®¡è®¡ (DA)
4. æ‰¹æ¬¡æ’¤é”€ (DO)
5. æ—¶é—´èŒƒå›´è¯æ˜

è¿è¡Œæ–¹å¼ï¼š
    python e2e_performance_benchmark.py
"""

import time
import json
import sys
import os
from typing import Dict, List, Tuple
import tracemalloc
import pickle

# Add parent directory to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from charm.toolbox.pairinggroup import ZR
from vc_smallness import setup, keygen_crs
from vds_owner import DataOwner
from vds_server import StorageServer
from vds_verifier import Verifier


class E2EPerformanceBenchmark:
    """ç«¯åˆ°ç«¯æ€§èƒ½åŸºå‡†æµ‹è¯•ç±»"""
    
    def __init__(self, curve='MNT224'):
        """åˆå§‹åŒ–åŸºå‡†æµ‹è¯•"""
        print(f"ğŸ”§ åˆå§‹åŒ–ç«¯åˆ°ç«¯æ€§èƒ½æµ‹è¯• (æ›²çº¿: {curve})...")
        self.params = setup(curve)
        self.group = self.params['group']
        self.results = {}
        self.bandwidth_results = {}
        
    def measure_time(self, func, *args, num_runs=10, **kwargs) -> Tuple[float, float, any]:
        """
        æµ‹é‡å‡½æ•°æ‰§è¡Œæ—¶é—´çš„å¹³å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆç§’ï¼‰

        Args:
            func: è¦æµ‹è¯•çš„å‡½æ•°
            num_runs: é‡å¤æµ‹è¯•æ¬¡æ•°ï¼ˆé»˜è®¤10æ¬¡ï¼‰
            *args, **kwargs: ä¼ é€’ç»™å‡½æ•°çš„å‚æ•°

        Returns:
            (å¹³å‡æ—¶é—´, æ ‡å‡†å·®, æœ€åä¸€æ¬¡æ‰§è¡Œç»“æœ)
        """
        times = []
        result = None

        for _ in range(num_runs):
            start = time.perf_counter()
            result = func(*args, **kwargs)
            end = time.perf_counter()
            times.append(end - start)

        avg_time = sum(times) / len(times)
        std_dev = (sum((t - avg_time)**2 for t in times) / len(times)) ** 0.5

        return avg_time, std_dev, result
    
    def measure_size(self, obj) -> int:
        """æµ‹é‡å¯¹è±¡åºåˆ—åŒ–åçš„å­—èŠ‚å¤§å°"""
        try:
            return len(pickle.dumps(obj))
        except:
            # å¦‚æœæ— æ³•åºåˆ—åŒ–ï¼Œè¿”å›å­—ç¬¦ä¸²é•¿åº¦çš„ä¼°è®¡
            return len(str(obj).encode())
    
    def benchmark_batch_creation(self, vector_sizes: List[int], num_runs=10):
        """
        åŸºå‡†æµ‹è¯•æ‰¹æ¬¡åˆ›å»ºçš„ç«¯åˆ°ç«¯æ€§èƒ½
        
        æµ‹è¯•æµç¨‹ï¼š
        1. DO åˆ›å»ºæ‰¹æ¬¡ (commit + sign)
        2. SS å­˜å‚¨æ‰¹æ¬¡
        """
        print("\nğŸ“Š æ‰¹æ¬¡åˆ›å»ºç«¯åˆ°ç«¯æ€§èƒ½æµ‹è¯• (æ¯ä¸ªæµ‹è¯•é‡å¤ {} æ¬¡)".format(num_runs))
        print("=" * 70)

        results = {
            'do_create_batch': {},
            'ss_store_batch': {},
            'total_batch_creation': {}
        }
        std_devs = {
            'do_create_batch': {},
            'ss_store_batch': {},
            'total_batch_creation': {}
        }
        bandwidth = {
            'public_header_size': {},
            'secrets_size': {}
        }

        for n in vector_sizes:
            print(f"  æµ‹è¯• n={n}...", end=" ", flush=True)
            
            # è®¾ç½®ç³»ç»Ÿ
            crs = keygen_crs(n, self.group)
            do = DataOwner(crs, self.group)
            initial_keys = do.get_initial_server_keys()
            ss = StorageServer(crs, initial_keys)
            
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            m_vector = [self.group.init(ZR, i + 10) for i in range(n)]
            t_vector = [self.group.init(ZR, i + 1) for i in range(n)]
            
            # æµ‹è¯• DO åˆ›å»ºæ‰¹æ¬¡
            def create_batch():
                return do.create_batch(m_vector, t_vector)
            
            t1, s1, (batch_id, public_header, secrets) = self.measure_time(
                create_batch, num_runs=num_runs
            )
            
            # æµ‹è¯• SS å­˜å‚¨æ‰¹æ¬¡
            def store_batch():
                ss.store_batch(batch_id, public_header, secrets)
            
            t2, s2, _ = self.measure_time(store_batch, num_runs=num_runs)
            
            # æ€»æ—¶é—´
            total_time = t1 + t2
            total_std = (s1**2 + s2**2) ** 0.5
            
            results['do_create_batch'][n] = t1
            results['ss_store_batch'][n] = t2
            results['total_batch_creation'][n] = total_time
            
            std_devs['do_create_batch'][n] = s1
            std_devs['ss_store_batch'][n] = s2
            std_devs['total_batch_creation'][n] = total_std
            
            # æµ‹é‡å¸¦å®½
            bandwidth['public_header_size'][n] = self.measure_size(public_header)
            bandwidth['secrets_size'][n] = self.measure_size(secrets)
            
            print(f"âœ“ DO:{t1*1000:.2f}Â±{s1*1000:.2f}ms SS:{t2*1000:.2f}Â±{s2*1000:.2f}ms æ€»:{total_time*1000:.2f}Â±{total_std*1000:.2f}ms")

        self.results['batch_creation'] = results
        self.results['batch_creation_std'] = std_devs
        self.bandwidth_results['batch_creation'] = bandwidth
        return results
    
    def benchmark_dc_query(self, vector_sizes: List[int], num_runs=10):
        """
        åŸºå‡†æµ‹è¯•æ•°æ®æ¶ˆè´¹è€…æŸ¥è¯¢çš„ç«¯åˆ°ç«¯æ€§èƒ½
        
        æµ‹è¯•æµç¨‹ï¼š
        1. DC å‘èµ·æŸ¥è¯¢ (æä¾›æŒ‘æˆ˜å‘é‡)
        2. SS ç”Ÿæˆè¯æ˜
        3. Verifier éªŒè¯è¯æ˜
        """
        print("\nğŸ“Š DC æŸ¥è¯¢ç«¯åˆ°ç«¯æ€§èƒ½æµ‹è¯• (æ¯ä¸ªæµ‹è¯•é‡å¤ {} æ¬¡)".format(num_runs))
        print("=" * 70)

        results = {
            'ss_generate_proof': {},
            'verifier_verify': {},
            'total_dc_query': {}
        }
        std_devs = {
            'ss_generate_proof': {},
            'verifier_verify': {},
            'total_dc_query': {}
        }
        bandwidth = {
            'proof_size': {},
            'result_size': {}
        }

        for n in vector_sizes:
            print(f"  æµ‹è¯• n={n}...", end=" ", flush=True)
            
            # è®¾ç½®ç³»ç»Ÿå¹¶åˆ›å»ºæ‰¹æ¬¡
            crs = keygen_crs(n, self.group)
            do = DataOwner(crs, self.group)
            initial_keys = do.get_initial_server_keys()
            ss = StorageServer(crs, initial_keys)
            global_pk = do.get_global_pk()
            verifier = Verifier(crs, global_pk, self.group)
            
            # åˆ›å»ºæ‰¹æ¬¡
            m_vector = [self.group.init(ZR, i + 10) for i in range(n)]
            t_vector = [self.group.init(ZR, i + 1) for i in range(n)]
            batch_id, public_header, secrets = do.create_batch(m_vector, t_vector)
            ss.store_batch(batch_id, public_header, secrets)
            
            # DC æŒ‘æˆ˜å‘é‡ (æ±‚å’Œ)
            t_challenge = [self.group.init(ZR, 1) for _ in range(n)]
            f_current = global_pk["f_current"]
            
            # æµ‹è¯• SS ç”Ÿæˆè¯æ˜
            def generate_proof():
                return ss.generate_dc_data_proof(batch_id, t_challenge, f_current)
            
            t1, s1, (x_result, pi_audit, pi_non) = self.measure_time(
                generate_proof, num_runs=num_runs
            )
            
            # æµ‹è¯• Verifier éªŒè¯
            def verify_proof():
                return verifier.verify_dc_query(
                    public_header, t_challenge, x_result, pi_audit, pi_non
                )
            
            t2, s2, is_valid = self.measure_time(verify_proof, num_runs=num_runs)
            
            # æ€»æ—¶é—´
            total_time = t1 + t2
            total_std = (s1**2 + s2**2) ** 0.5
            
            results['ss_generate_proof'][n] = t1
            results['verifier_verify'][n] = t2
            results['total_dc_query'][n] = total_time
            
            std_devs['ss_generate_proof'][n] = s1
            std_devs['verifier_verify'][n] = s2
            std_devs['total_dc_query'][n] = total_std
            
            # æµ‹é‡å¸¦å®½
            proof_size = self.measure_size(pi_audit) + self.measure_size(pi_non)
            bandwidth['proof_size'][n] = proof_size
            bandwidth['result_size'][n] = self.measure_size(x_result)
            
            status = "âœ“" if is_valid else "âœ—"
            print(f"{status} SS:{t1*1000:.2f}Â±{s1*1000:.2f}ms Ver:{t2*1000:.2f}Â±{s2*1000:.2f}ms æ€»:{total_time*1000:.2f}Â±{total_std*1000:.2f}ms")

        self.results['dc_query'] = results
        self.results['dc_query_std'] = std_devs
        self.bandwidth_results['dc_query'] = bandwidth
        return results
    
    def benchmark_da_audit(self, vector_sizes: List[int], num_runs=10):
        """
        åŸºå‡†æµ‹è¯•å®¡è®¡å‘˜å®¡è®¡çš„ç«¯åˆ°ç«¯æ€§èƒ½
        
        æµ‹è¯•æµç¨‹ï¼š
        1. SS ç”Ÿæˆé›¶çŸ¥è¯†å®¡è®¡è¯æ˜
        2. Verifier éªŒè¯è¯æ˜
        """
        print("\nğŸ“Š DA å®¡è®¡ç«¯åˆ°ç«¯æ€§èƒ½æµ‹è¯• (æ¯ä¸ªæµ‹è¯•é‡å¤ {} æ¬¡)".format(num_runs))
        print("=" * 70)

        results = {
            'ss_generate_audit_proof': {},
            'verifier_verify_audit': {},
            'total_da_audit': {}
        }
        std_devs = {
            'ss_generate_audit_proof': {},
            'verifier_verify_audit': {},
            'total_da_audit': {}
        }
        bandwidth = {
            'audit_proof_size': {},
            'challenge_size': {}
        }

        for n in vector_sizes:
            print(f"  æµ‹è¯• n={n}...", end=" ", flush=True)
            
            # è®¾ç½®ç³»ç»Ÿå¹¶åˆ›å»ºæ‰¹æ¬¡
            crs = keygen_crs(n, self.group)
            do = DataOwner(crs, self.group)
            initial_keys = do.get_initial_server_keys()
            ss = StorageServer(crs, initial_keys)
            global_pk = do.get_global_pk()
            verifier = Verifier(crs, global_pk, self.group)
            
            # åˆ›å»ºæ‰¹æ¬¡
            m_vector = [self.group.init(ZR, i + 10) for i in range(n)]
            t_vector = [self.group.init(ZR, i + 1) for i in range(n)]
            batch_id, public_header, secrets = do.create_batch(m_vector, t_vector)
            ss.store_batch(batch_id, public_header, secrets)
            
            f_current = global_pk["f_current"]
            
            # æµ‹è¯• SS ç”Ÿæˆå®¡è®¡è¯æ˜
            def generate_audit_proof():
                return ss.generate_da_audit_proof(batch_id, f_current)
            
            t1, s1, (x_result, pi_audit, t_challenge, pi_non) = self.measure_time(
                generate_audit_proof, num_runs=num_runs
            )
            
            # æµ‹è¯• Verifier éªŒè¯
            def verify_audit():
                return verifier.verify_da_audit(
                    public_header, n, x_result, pi_audit, t_challenge, pi_non
                )
            
            t2, s2, is_valid = self.measure_time(verify_audit, num_runs=num_runs)
            
            # æ€»æ—¶é—´
            total_time = t1 + t2
            total_std = (s1**2 + s2**2) ** 0.5
            
            results['ss_generate_audit_proof'][n] = t1
            results['verifier_verify_audit'][n] = t2
            results['total_da_audit'][n] = total_time
            
            std_devs['ss_generate_audit_proof'][n] = s1
            std_devs['verifier_verify_audit'][n] = s2
            std_devs['total_da_audit'][n] = total_std
            
            # æµ‹é‡å¸¦å®½
            audit_proof_size = self.measure_size(pi_audit) + self.measure_size(pi_non)
            bandwidth['audit_proof_size'][n] = audit_proof_size
            bandwidth['challenge_size'][n] = self.measure_size(t_challenge)
            
            status = "âœ“" if is_valid else "âœ—"
            print(f"{status} SS:{t1*1000:.2f}Â±{s1*1000:.2f}ms Ver:{t2*1000:.2f}Â±{s2*1000:.2f}ms æ€»:{total_time*1000:.2f}Â±{total_std*1000:.2f}ms")

        self.results['da_audit'] = results
        self.results['da_audit_std'] = std_devs
        self.bandwidth_results['da_audit'] = bandwidth
        return results

    def benchmark_revocation(self, vector_sizes: List[int], num_runs=10):
        """
        åŸºå‡†æµ‹è¯•æ‰¹æ¬¡æ’¤é”€çš„ç«¯åˆ°ç«¯æ€§èƒ½

        æµ‹è¯•æµç¨‹ï¼š
        1. DO æ’¤é”€æ‰¹æ¬¡
        2. SS æ›´æ–°å¯†é’¥
        3. Verifier æ›´æ–° global_pk
        4. éªŒè¯æ’¤é”€åçš„æŸ¥è¯¢å¤±è´¥
        """
        print("\nğŸ“Š æ‰¹æ¬¡æ’¤é”€ç«¯åˆ°ç«¯æ€§èƒ½æµ‹è¯• (æ¯ä¸ªæµ‹è¯•é‡å¤ {} æ¬¡)".format(num_runs))
        print("=" * 70)

        results = {
            'do_revoke_batch': {},
            'ss_update_keys': {},
            'verifier_update_pk': {},
            'verify_revoked_batch': {},
            'total_revocation': {}
        }
        std_devs = {
            'do_revoke_batch': {},
            'ss_update_keys': {},
            'verifier_update_pk': {},
            'verify_revoked_batch': {},
            'total_revocation': {}
        }
        bandwidth = {
            'new_key_size': {},
            'new_pk_size': {}
        }

        for n in vector_sizes:
            print(f"  æµ‹è¯• n={n}...", end=" ", flush=True)

            # è®¾ç½®ç³»ç»Ÿå¹¶åˆ›å»ºæ‰¹æ¬¡
            crs = keygen_crs(n, self.group)
            do = DataOwner(crs, self.group)
            initial_keys = do.get_initial_server_keys()
            ss = StorageServer(crs, initial_keys)
            global_pk = do.get_global_pk()
            verifier = Verifier(crs, global_pk, self.group)

            # åˆ›å»ºæ‰¹æ¬¡
            m_vector = [self.group.init(ZR, i + 10) for i in range(n)]
            t_vector = [self.group.init(ZR, i + 1) for i in range(n)]
            batch_id, public_header, secrets = do.create_batch(m_vector, t_vector)
            ss.store_batch(batch_id, public_header, secrets)

            sigma_to_revoke = public_header["sigma"]

            # æµ‹è¯• DO æ’¤é”€æ‰¹æ¬¡
            def revoke_batch():
                return do.revoke_batch(sigma_to_revoke)

            t1, s1, (g_s_q_new, new_global_pk) = self.measure_time(
                revoke_batch, num_runs=num_runs
            )

            # æµ‹è¯• SS æ›´æ–°å¯†é’¥
            def update_ss_keys():
                ss.add_server_key(g_s_q_new)

            t2, s2, _ = self.measure_time(update_ss_keys, num_runs=num_runs)

            # æµ‹è¯• Verifier æ›´æ–° global_pk
            def update_verifier_pk():
                verifier.update_global_pk(new_global_pk)

            t3, s3, _ = self.measure_time(update_verifier_pk, num_runs=num_runs)

            # æµ‹è¯•éªŒè¯æ’¤é”€åçš„æ‰¹æ¬¡
            t_challenge = [self.group.init(ZR, 1) for _ in range(n)]
            f_current_new = new_global_pk["f_current"]
            x_result, pi_audit, pi_non = ss.generate_dc_data_proof(
                batch_id, t_challenge, f_current_new
            )

            def verify_revoked():
                return verifier.verify_dc_query(
                    public_header, t_challenge, x_result, pi_audit, pi_non
                )

            t4, s4, is_valid = self.measure_time(verify_revoked, num_runs=num_runs)

            # æ€»æ—¶é—´
            total_time = t1 + t2 + t3 + t4
            total_std = (s1**2 + s2**2 + s3**2 + s4**2) ** 0.5

            results['do_revoke_batch'][n] = t1
            results['ss_update_keys'][n] = t2
            results['verifier_update_pk'][n] = t3
            results['verify_revoked_batch'][n] = t4
            results['total_revocation'][n] = total_time

            std_devs['do_revoke_batch'][n] = s1
            std_devs['ss_update_keys'][n] = s2
            std_devs['verifier_update_pk'][n] = s3
            std_devs['verify_revoked_batch'][n] = s4
            std_devs['total_revocation'][n] = total_std

            # æµ‹é‡å¸¦å®½
            bandwidth['new_key_size'][n] = self.measure_size(g_s_q_new)
            bandwidth['new_pk_size'][n] = self.measure_size(new_global_pk)

            status = "âœ“" if not is_valid else "âœ—"  # æ’¤é”€ååº”è¯¥éªŒè¯å¤±è´¥
            print(f"{status} DO:{t1*1000:.2f}Â±{s1*1000:.2f}ms SS:{t2*1000:.2f}Â±{s2*1000:.2f}ms Ver:{t3*1000:.2f}Â±{s3*1000:.2f}ms æ€»:{total_time*1000:.2f}Â±{total_std*1000:.2f}ms")

        self.results['revocation'] = results
        self.results['revocation_std'] = std_devs
        self.bandwidth_results['revocation'] = bandwidth
        return results

    def benchmark_time_range_proof(self, vector_sizes: List[int], num_runs=10):
        """
        åŸºå‡†æµ‹è¯•æ—¶é—´èŒƒå›´è¯æ˜çš„ç«¯åˆ°ç«¯æ€§èƒ½

        æµ‹è¯•æµç¨‹ï¼š
        1. SS ç”Ÿæˆæ—¶é—´èŒƒå›´è¯æ˜
        2. Verifier éªŒè¯æ—¶é—´èŒƒå›´è¯æ˜
        """
        print("\nğŸ“Š æ—¶é—´èŒƒå›´è¯æ˜ç«¯åˆ°ç«¯æ€§èƒ½æµ‹è¯• (æ¯ä¸ªæµ‹è¯•é‡å¤ {} æ¬¡)".format(num_runs))
        print("=" * 70)

        results = {
            'ss_generate_time_proof': {},
            'verifier_verify_time_proof': {},
            'total_time_range_proof': {}
        }
        std_devs = {
            'ss_generate_time_proof': {},
            'verifier_verify_time_proof': {},
            'total_time_range_proof': {}
        }
        bandwidth = {
            'time_proof_size': {}
        }

        for n in vector_sizes:
            print(f"  æµ‹è¯• n={n}...", end=" ", flush=True)

            # è®¾ç½®ç³»ç»Ÿå¹¶åˆ›å»ºæ‰¹æ¬¡
            crs = keygen_crs(n, self.group)
            do = DataOwner(crs, self.group)
            initial_keys = do.get_initial_server_keys()
            ss = StorageServer(crs, initial_keys)
            global_pk = do.get_global_pk()
            verifier = Verifier(crs, global_pk, self.group)

            # åˆ›å»ºæ‰¹æ¬¡
            m_vector = [self.group.init(ZR, i + 10) for i in range(n)]
            t_vector = [self.group.init(ZR, i + 1) for i in range(n)]
            batch_id, public_header, secrets = do.create_batch(m_vector, t_vector)
            ss.store_batch(batch_id, public_header, secrets)

            f_current = global_pk["f_current"]

            # æµ‹è¯• SS ç”Ÿæˆæ—¶é—´èŒƒå›´è¯æ˜
            def generate_time_proof():
                return ss.generate_time_range_proofs(batch_id, f_current)

            t1, s1, time_proofs = self.measure_time(
                generate_time_proof, num_runs=num_runs
            )

            # æµ‹è¯• Verifier éªŒè¯æ—¶é—´èŒƒå›´è¯æ˜
            def verify_time_proofs():
                results = []
                for proof_data in time_proofs:
                    is_valid = verifier.verify_time_range_proof(
                        public_header, proof_data, f_current
                    )
                    results.append(is_valid)
                return all(results)

            t2, s2, all_valid = self.measure_time(verify_time_proofs, num_runs=num_runs)

            # æ€»æ—¶é—´
            total_time = t1 + t2
            total_std = (s1**2 + s2**2) ** 0.5

            results['ss_generate_time_proof'][n] = t1
            results['verifier_verify_time_proof'][n] = t2
            results['total_time_range_proof'][n] = total_time

            std_devs['ss_generate_time_proof'][n] = s1
            std_devs['verifier_verify_time_proof'][n] = s2
            std_devs['total_time_range_proof'][n] = total_std

            # æµ‹é‡å¸¦å®½
            bandwidth['time_proof_size'][n] = sum(
                self.measure_size(proof) for proof in time_proofs
            )

            status = "âœ“" if all_valid else "âœ—"
            print(f"{status} SS:{t1*1000:.2f}Â±{s1*1000:.2f}ms Ver:{t2*1000:.2f}Â±{s2*1000:.2f}ms æ€»:{total_time*1000:.2f}Â±{total_std*1000:.2f}ms")

        self.results['time_range_proof'] = results
        self.results['time_range_proof_std'] = std_devs
        self.bandwidth_results['time_range_proof'] = bandwidth
        return results

    def save_results(self, filename='e2e_benchmark_results.json'):
        """ä¿å­˜æµ‹è¯•ç»“æœåˆ° JSON æ–‡ä»¶"""
        output = {
            'performance': self.results,
            'bandwidth': self.bandwidth_results
        }

        with open(filename, 'w') as f:
            json.dump(output, f, indent=2)

        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")

    def print_summary(self):
        """æ‰“å°æµ‹è¯•ç»“æœæ‘˜è¦"""
        print("\n" + "=" * 70)
        print("ğŸ“Š ç«¯åˆ°ç«¯æ€§èƒ½æµ‹è¯•æ‘˜è¦")
        print("=" * 70)

        # æ‰¹æ¬¡åˆ›å»ºæ‘˜è¦
        if 'batch_creation' in self.results:
            print("\n1ï¸âƒ£  æ‰¹æ¬¡åˆ›å»º:")
            for n, time in self.results['batch_creation']['total_batch_creation'].items():
                std = self.results['batch_creation_std']['total_batch_creation'][n]
                header_size = self.bandwidth_results['batch_creation']['public_header_size'][n]
                secrets_size = self.bandwidth_results['batch_creation']['secrets_size'][n]
                print(f"   n={n:2d}: {time*1000:6.2f}Â±{std*1000:5.2f}ms | "
                      f"Header:{header_size/1024:6.2f}KB Secrets:{secrets_size/1024:6.2f}KB")

        # DC æŸ¥è¯¢æ‘˜è¦
        if 'dc_query' in self.results:
            print("\n2ï¸âƒ£  DC æŸ¥è¯¢:")
            for n, time in self.results['dc_query']['total_dc_query'].items():
                std = self.results['dc_query_std']['total_dc_query'][n]
                proof_size = self.bandwidth_results['dc_query']['proof_size'][n]
                print(f"   n={n:2d}: {time*1000:6.2f}Â±{std*1000:5.2f}ms | "
                      f"Proof:{proof_size/1024:6.2f}KB")

        # DA å®¡è®¡æ‘˜è¦
        if 'da_audit' in self.results:
            print("\n3ï¸âƒ£  DA å®¡è®¡:")
            for n, time in self.results['da_audit']['total_da_audit'].items():
                std = self.results['da_audit_std']['total_da_audit'][n]
                proof_size = self.bandwidth_results['da_audit']['audit_proof_size'][n]
                print(f"   n={n:2d}: {time*1000:6.2f}Â±{std*1000:5.2f}ms | "
                      f"Proof:{proof_size/1024:6.2f}KB")

        # æ’¤é”€æ‘˜è¦
        if 'revocation' in self.results:
            print("\n4ï¸âƒ£  æ‰¹æ¬¡æ’¤é”€:")
            for n, time in self.results['revocation']['total_revocation'].items():
                std = self.results['revocation_std']['total_revocation'][n]
                key_size = self.bandwidth_results['revocation']['new_key_size'][n]
                print(f"   n={n:2d}: {time*1000:6.2f}Â±{std*1000:5.2f}ms | "
                      f"NewKey:{key_size/1024:6.2f}KB")

        # æ—¶é—´èŒƒå›´è¯æ˜æ‘˜è¦
        if 'time_range_proof' in self.results:
            print("\n5ï¸âƒ£  æ—¶é—´èŒƒå›´è¯æ˜:")
            for n, time in self.results['time_range_proof']['total_time_range_proof'].items():
                std = self.results['time_range_proof_std']['total_time_range_proof'][n]
                proof_size = self.bandwidth_results['time_range_proof']['time_proof_size'][n]
                print(f"   n={n:2d}: {time*1000:6.2f}Â±{std*1000:5.2f}ms | "
                      f"Proof:{proof_size/1024:6.2f}KB")

        print("\n" + "=" * 70)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ VDS Scheme C+ ç«¯åˆ°ç«¯æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 70)

    # åˆå§‹åŒ–æµ‹è¯•
    benchmark = E2EPerformanceBenchmark(curve='MNT224')

    # æµ‹è¯•å‘é‡å¤§å°
    vector_sizes = [4, 8, 16]
    num_runs = 10

    print(f"\nğŸ“‹ æµ‹è¯•é…ç½®:")
    print(f"   - å‘é‡å¤§å°: {vector_sizes}")
    print(f"   - æ¯ä¸ªæµ‹è¯•é‡å¤: {num_runs} æ¬¡")
    print(f"   - æ›²çº¿: MNT224")

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    benchmark.benchmark_batch_creation(vector_sizes, num_runs)
    benchmark.benchmark_dc_query(vector_sizes, num_runs)
    benchmark.benchmark_da_audit(vector_sizes, num_runs)
    benchmark.benchmark_revocation(vector_sizes, num_runs)
    benchmark.benchmark_time_range_proof(vector_sizes, num_runs)

    # æ‰“å°æ‘˜è¦
    benchmark.print_summary()

    # ä¿å­˜ç»“æœ
    benchmark.save_results('e2e_benchmark_results.json')

    print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")


if __name__ == '__main__':
    main()


