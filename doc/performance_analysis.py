"""
æ€§èƒ½åˆ†æå’Œå¯è§†åŒ– / Performance Analysis and Visualization
=========================================================

ç”Ÿæˆæ€§èƒ½åˆ†æå›¾è¡¨ï¼ŒåŒ…æ‹¬ï¼š
- æ‰§è¡Œæ—¶é—´å¯¹æ¯”
- å†…å­˜ä½¿ç”¨è¶‹åŠ¿
- æ€§èƒ½æ‰©å±•åˆ†æ
- æ“ä½œå¤æ‚åº¦åˆ†æ

è¿è¡Œæ–¹å¼ï¼š
    python performance_analysis.py
"""

import json
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from matplotlib import rcParams
import numpy as np
from typing import Dict, List

# è®¾ç½®ä¸­æ–‡å­—ä½“
rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS', 'SimHei']
rcParams['axes.unicode_minus'] = False


class PerformanceAnalyzer:
    """æ€§èƒ½åˆ†æç±»"""

    def __init__(self, results_file='benchmark_results.json'):
        """åŠ è½½åŸºå‡†æµ‹è¯•ç»“æœ"""
        try:
            with open(results_file, 'r') as f:
                data = json.load(f)
                self.timing_results = data.get('timing', {})
                self.memory_results = data.get('memory', {})
        except FileNotFoundError:
            print(f"âŒ æ‰¾ä¸åˆ°ç»“æœæ–‡ä»¶: {results_file}")
            print("è¯·å…ˆè¿è¡Œ: python performance_benchmark.py")
            exit(1)
    
    def plot_crs_generation(self):
        """ç»˜åˆ¶ CRS ç”Ÿæˆæ€§èƒ½"""
        print("ğŸ“Š ç»˜åˆ¶ CRS ç”Ÿæˆæ€§èƒ½å›¾è¡¨...")
        
        data = self.timing_results.get('crs_generation', {})
        if not data:
            print("âš ï¸  æ²¡æœ‰ CRS ç”Ÿæˆæ•°æ®")
            return
        
        n_values = sorted([int(k) for k in data.keys()])
        times = [data[str(n)] * 1000 for n in n_values]  # è½¬æ¢ä¸º ms
        
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.plot(n_values, times, 'o-', linewidth=2, markersize=8, color='#2E86AB', label='CRS Generation')
        ax.fill_between(n_values, times, alpha=0.3, color='#2E86AB')
        
        ax.set_xlabel('Vector Size (n)', fontsize=12, fontweight='bold')
        ax.set_ylabel('Time (ms)', fontsize=12, fontweight='bold')
        ax.set_title('CRS Generation Performance', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=11)
        
        plt.tight_layout()
        plt.savefig('perf_crs_generation.png', dpi=300, bbox_inches='tight')
        print("âœ… å·²ä¿å­˜: perf_crs_generation.png")
        plt.close()
    
    def plot_commitments_comparison(self):
        """ç»˜åˆ¶æ‰¿è¯ºç”Ÿæˆå¯¹æ¯”"""
        print("ğŸ“Š ç»˜åˆ¶æ‰¿è¯ºç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
        
        data = self.timing_results.get('commitments', {})
        if not data:
            print("âš ï¸  æ²¡æœ‰æ‰¿è¯ºæ•°æ®")
            return
        
        fig, ax = plt.subplots(figsize=(12, 7))
        
        n_values = sorted([int(k) for k in data['commit_G'].keys()])
        colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D']
        
        for (name, color) in zip(['commit_G', 'commit_Ghat', 'commit_Cy', 'commit_V'], colors):
            times = [data[name][str(n)] * 1000 for n in n_values]
            ax.plot(n_values, times, 'o-', linewidth=2, markersize=8, label=name, color=color)
        
        ax.set_xlabel('Vector Size (n)', fontsize=12, fontweight='bold')
        ax.set_ylabel('Time (ms)', fontsize=12, fontweight='bold')
        ax.set_title('Commitment Generation Performance Comparison', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=10)
        
        plt.tight_layout()
        plt.savefig('perf_commitments.png', dpi=300, bbox_inches='tight')
        print("âœ… å·²ä¿å­˜: perf_commitments.png")
        plt.close()
    
    def plot_proofs_comparison(self):
        """ç»˜åˆ¶è¯æ˜ç”Ÿæˆå¯¹æ¯”"""
        print("ğŸ“Š ç»˜åˆ¶è¯æ˜ç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
        
        data = self.timing_results.get('proofs', {})
        if not data:
            print("âš ï¸  æ²¡æœ‰è¯æ˜æ•°æ®")
            return
        
        fig, ax = plt.subplots(figsize=(12, 7))
        
        n_values = sorted([int(k) for k in data['point_open'].keys()])
        colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6A994E']
        
        for (name, color) in zip(['point_open', 'agg_open', 'equality', 'orthogonality', 'range'], colors):
            times = [data[name][str(n)] * 1000 for n in n_values]
            ax.plot(n_values, times, 'o-', linewidth=2, markersize=8, label=name, color=color)
        
        ax.set_xlabel('Vector Size (n)', fontsize=12, fontweight='bold')
        ax.set_ylabel('Time (ms)', fontsize=12, fontweight='bold')
        ax.set_title('Proof Generation Performance Comparison', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=10)
        
        plt.tight_layout()
        plt.savefig('perf_proofs.png', dpi=300, bbox_inches='tight')
        print("âœ… å·²ä¿å­˜: perf_proofs.png")
        plt.close()
    
    def plot_verification_comparison(self):
        """ç»˜åˆ¶éªŒè¯æ€§èƒ½å¯¹æ¯”"""
        print("ğŸ“Š ç»˜åˆ¶éªŒè¯æ€§èƒ½å¯¹æ¯”å›¾è¡¨...")
        
        data = self.timing_results.get('verification', {})
        if not data:
            print("âš ï¸  æ²¡æœ‰éªŒè¯æ•°æ®")
            return
        
        fig, ax = plt.subplots(figsize=(12, 7))
        
        n_values = sorted([int(k) for k in data['verify_1'].keys()])
        colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6A994E']
        
        for (name, color) in zip(['verify_1', 'verify_5', 'verify_7', 'verify_9', 'verify_16'], colors):
            times = [data[name][str(n)] * 1000 for n in n_values]
            ax.plot(n_values, times, 'o-', linewidth=2, markersize=8, label=name, color=color)
        
        ax.set_xlabel('Vector Size (n)', fontsize=12, fontweight='bold')
        ax.set_ylabel('Time (ms)', fontsize=12, fontweight='bold')
        ax.set_title('Verification Performance Comparison', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=10)
        
        plt.tight_layout()
        plt.savefig('perf_verification.png', dpi=300, bbox_inches='tight')
        print("âœ… å·²ä¿å­˜: perf_verification.png")
        plt.close()
    
    def plot_memory_usage(self):
        """ç»˜åˆ¶å†…å­˜ä½¿ç”¨"""
        print("ğŸ“Š ç»˜åˆ¶å†…å­˜ä½¿ç”¨å›¾è¡¨...")
        
        data = self.memory_results.get('crs', {})
        if not data:
            print("âš ï¸  æ²¡æœ‰å†…å­˜æ•°æ®")
            return
        
        n_values = sorted([int(k) for k in data.keys()])
        memory = [data[str(n)] for n in n_values]
        
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.bar(range(len(n_values)), memory, color='#2E86AB', alpha=0.7, edgecolor='black', linewidth=1.5)
        ax.set_xticks(range(len(n_values)))
        ax.set_xticklabels([f'n={n}' for n in n_values])
        
        ax.set_xlabel('Vector Size (n)', fontsize=12, fontweight='bold')
        ax.set_ylabel('Memory Usage (MB)', fontsize=12, fontweight='bold')
        ax.set_title('CRS Memory Usage', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3, axis='y')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, v in enumerate(memory):
            ax.text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('perf_memory.png', dpi=300, bbox_inches='tight')
        print("âœ… å·²ä¿å­˜: perf_memory.png")
        plt.close()
    
    def plot_complexity_analysis(self):
        """ç»˜åˆ¶å¤æ‚åº¦åˆ†æ"""
        print("ğŸ“Š ç»˜åˆ¶å¤æ‚åº¦åˆ†æå›¾è¡¨...")
        
        data = self.timing_results.get('commitments', {})
        if not data:
            print("âš ï¸  æ²¡æœ‰æ•°æ®")
            return
        
        n_values = sorted([int(k) for k in data['commit_G'].keys()])
        times = [data['commit_G'][str(n)] * 1000 for n in n_values]
        
        # æ‹Ÿåˆ O(n) å’Œ O(n log n)
        fig, ax = plt.subplots(figsize=(12, 7))
        
        # å®é™…æ•°æ®
        ax.plot(n_values, times, 'o-', linewidth=2, markersize=8, label='Actual (commit_G)', color='#2E86AB')
        
        # ç†è®ºå¤æ‚åº¦
        if len(n_values) >= 2:
            # è®¡ç®— O(n) çš„ç³»æ•°
            coeff_n = times[0] / n_values[0]
            linear = [coeff_n * n for n in n_values]
            ax.plot(n_values, linear, '--', linewidth=2, label='O(n) fit', color='#F18F01', alpha=0.7)
            
            # è®¡ç®— O(n log n) çš„ç³»æ•°
            coeff_nlogn = times[0] / (n_values[0] * np.log(n_values[0]))
            nlogn = [coeff_nlogn * n * np.log(n) for n in n_values]
            ax.plot(n_values, nlogn, ':', linewidth=2, label='O(n log n) fit', color='#C73E1D', alpha=0.7)
        
        ax.set_xlabel('Vector Size (n)', fontsize=12, fontweight='bold')
        ax.set_ylabel('Time (ms)', fontsize=12, fontweight='bold')
        ax.set_title('Complexity Analysis: Commitment Generation', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=11)
        
        plt.tight_layout()
        plt.savefig('perf_complexity.png', dpi=300, bbox_inches='tight')
        print("âœ… å·²ä¿å­˜: perf_complexity.png")
        plt.close()
    
    def plot_overall_summary(self):
        """ç»˜åˆ¶æ€»ä½“æ€§èƒ½æ€»ç»“"""
        print("ğŸ“Š ç»˜åˆ¶æ€»ä½“æ€§èƒ½æ€»ç»“å›¾è¡¨...")
        
        # è·å–æœ€å¤§å‘é‡å¤§å°çš„æ•°æ®
        data_commit = self.timing_results.get('commitments', {})
        data_proof = self.timing_results.get('proofs', {})
        data_verify = self.timing_results.get('verification', {})
        
        if not (data_commit and data_proof and data_verify):
            print("âš ï¸  æ•°æ®ä¸å®Œæ•´")
            return
        
        # è·å–æœ€å¤§ n å€¼
        max_n = max(
            max(int(k) for k in data_commit['commit_G'].keys()),
            max(int(k) for k in data_proof['point_open'].keys()),
            max(int(k) for k in data_verify['verify_1'].keys())
        )
        
        # è·å–æœ€å¤§ n çš„æ•°æ®
        max_n_str = str(max_n)
        
        categories = ['Commit_G', 'Commit_Ghat', 'Commit_Cy', 'Point_Open', 'Agg_Open', 'Verify_1', 'Verify_5']
        times = [
            data_commit['commit_G'][max_n_str] * 1000,
            data_commit['commit_Ghat'][max_n_str] * 1000,
            data_commit['commit_Cy'][max_n_str] * 1000,
            data_proof['point_open'][max_n_str] * 1000,
            data_proof['agg_open'][max_n_str] * 1000,
            data_verify['verify_1'][max_n_str] * 1000,
            data_verify['verify_5'][max_n_str] * 1000,
        ]
        
        fig, ax = plt.subplots(figsize=(14, 7))
        colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6A994E', '#D62828', '#F77F00']
        bars = ax.barh(categories, times, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)
        
        ax.set_xlabel('Time (ms)', fontsize=12, fontweight='bold')
        ax.set_title(f'Overall Performance Summary (n={max_n})', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3, axis='x')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, time) in enumerate(zip(bars, times)):
            ax.text(time + 0.1, i, f'{time:.2f}ms', va='center', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('perf_summary.png', dpi=300, bbox_inches='tight')
        print("âœ… å·²ä¿å­˜: perf_summary.png")
        plt.close()
    
    def generate_all_plots(self):
        """ç”Ÿæˆæ‰€æœ‰å›¾è¡¨"""
        print("\n" + "="*60)
        print("ğŸ¨ å¼€å§‹ç”Ÿæˆæ€§èƒ½åˆ†æå›¾è¡¨")
        print("="*60 + "\n")
        
        self.plot_crs_generation()
        self.plot_commitments_comparison()
        self.plot_proofs_comparison()
        self.plot_verification_comparison()
        self.plot_memory_usage()
        self.plot_complexity_analysis()
        self.plot_overall_summary()
        
        print("\n" + "="*60)
        print("âœ… æ‰€æœ‰å›¾è¡¨å·²ç”Ÿæˆ")
        print("="*60)


if __name__ == '__main__':
    analyzer = PerformanceAnalyzer()
    analyzer.generate_all_plots()

