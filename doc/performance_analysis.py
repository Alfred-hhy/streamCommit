"""
æ€§èƒ½åˆ†æå’Œå¯è§†åŒ– / Performance Analysis and Visualization
=========================================================

ç”Ÿæˆæ€§èƒ½åˆ†æå›¾è¡¨ï¼ŒåŒ…æ‹¬ï¼š
- æ‰§è¡Œæ—¶é—´å¯¹æ¯”
- å†…å­˜ä½¿ç”¨è¶‹åŠ¿
- æ€§èƒ½æ‰©å±•åˆ†æ
- æ“ä½œå¤æ‚åº¦åˆ†æ

è¿è¡Œæ–¹å¼ï¼š
    python performance_analysis.py
"""

import json
import sys
import os
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from matplotlib import rcParams
import numpy as np
from typing import Dict, List

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# è®¾ç½®ä¸­æ–‡å­—ä½“
rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS', 'SimHei']
rcParams['axes.unicode_minus'] = False


class PerformanceAnalyzer:
    """æ€§èƒ½åˆ†æç±»"""

    def __init__(self, results_file='try1028/benchmark_results.json'):
        """åŠ è½½åŸºå‡†æµ‹è¯•ç»“æœ"""
        try:
            with open(results_file, 'r') as f:
                data = json.load(f)
                self.timing_results = data.get('timing', {})
                self.memory_results = data.get('memory', {})
        except FileNotFoundError:
            print(f"âŒ æ‰¾ä¸åˆ°ç»“æœæ–‡ä»¶: {results_file}")
            print("è¯·å…ˆè¿è¡Œ: python performance_benchmark.py")
            exit(1)
    
    def plot_crs_generation(self):
        """ç»˜åˆ¶ CRS ç”Ÿæˆæ€§èƒ½"""
        print("ğŸ“Š ç»˜åˆ¶ CRS ç”Ÿæˆæ€§èƒ½å›¾è¡¨...")
        
        data = self.timing_results.get('crs_generation', {})
        if not data:
            print("âš ï¸  æ²¡æœ‰ CRS ç”Ÿæˆæ•°æ®")
            return
        
        n_values = sorted([int(k) for k in data.keys()])
        times = [data[str(n)] * 1000 for n in n_values]  # è½¬æ¢ä¸º ms
        
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.plot(n_values, times, 'o-', linewidth=2, markersize=8, color='#2E86AB', label='CRS Generation')
        ax.fill_between(n_values, times, alpha=0.3, color='#2E86AB')
        
        ax.set_xlabel('Vector Size (n)', fontsize=12, fontweight='bold')
        ax.set_ylabel('Time (ms)', fontsize=12, fontweight='bold')
        ax.set_title('CRS Generation Performance', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=11)
        
        plt.tight_layout()
        plt.savefig('perf_crs_generation.png', dpi=300, bbox_inches='tight')
        print("âœ… å·²ä¿å­˜: perf_crs_generation.png")
        plt.close()
    
    def plot_commitments_comparison(self):
        """ç»˜åˆ¶æ‰¿è¯ºç”Ÿæˆå¯¹æ¯”"""
        print("ğŸ“Š ç»˜åˆ¶æ‰¿è¯ºç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
        
        data = self.timing_results.get('commitments', {})
        if not data:
            print("âš ï¸  æ²¡æœ‰æ‰¿è¯ºæ•°æ®")
            return
        
        fig, ax = plt.subplots(figsize=(12, 7))
        
        n_values = sorted([int(k) for k in data['commit_G'].keys()])
        colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D']
        
        for (name, color) in zip(['commit_G', 'commit_Ghat', 'commit_Cy', 'commit_V'], colors):
            times = [data[name][str(n)] * 1000 for n in n_values]
            ax.plot(n_values, times, 'o-', linewidth=2, markersize=8, label=name, color=color)
        
        ax.set_xlabel('Vector Size (n)', fontsize=12, fontweight='bold')
        ax.set_ylabel('Time (ms)', fontsize=12, fontweight='bold')
        ax.set_title('Commitment Generation Performance Comparison', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=10)
        
        plt.tight_layout()
        plt.savefig('perf_commitments.png', dpi=300, bbox_inches='tight')
        print("âœ… å·²ä¿å­˜: perf_commitments.png")
        plt.close()
    
    def plot_proofs_comparison(self):
        """ç»˜åˆ¶è¯æ˜ç”Ÿæˆå¯¹æ¯”"""
        print("ğŸ“Š ç»˜åˆ¶è¯æ˜ç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
        
        data = self.timing_results.get('proofs', {})
        if not data:
            print("âš ï¸  æ²¡æœ‰è¯æ˜æ•°æ®")
            return
        
        fig, ax = plt.subplots(figsize=(12, 7))
        
        n_values = sorted([int(k) for k in data['point_open'].keys()])
        colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6A994E']
        
        for (name, color) in zip(['point_open', 'agg_open', 'equality', 'orthogonality', 'range'], colors):
            times = [data[name][str(n)] * 1000 for n in n_values]
            ax.plot(n_values, times, 'o-', linewidth=2, markersize=8, label=name, color=color)
        
        ax.set_xlabel('Vector Size (n)', fontsize=12, fontweight='bold')
        ax.set_ylabel('Time (ms)', fontsize=12, fontweight='bold')
        ax.set_title('Proof Generation Performance Comparison', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=10)
        
        plt.tight_layout()
        plt.savefig('perf_proofs.png', dpi=300, bbox_inches='tight')
        print("âœ… å·²ä¿å­˜: perf_proofs.png")
        plt.close()
    
    def plot_verification_comparison(self):
        """ç»˜åˆ¶éªŒè¯æ€§èƒ½å¯¹æ¯”"""
        print("ğŸ“Š ç»˜åˆ¶éªŒè¯æ€§èƒ½å¯¹æ¯”å›¾è¡¨...")

        data = self.timing_results.get('verification', {})
        if not data:
            print("âš ï¸  æ²¡æœ‰éªŒè¯æ•°æ®")
            return

        fig, ax = plt.subplots(figsize=(12, 7))

        # ä½¿ç”¨æ­£ç¡®çš„é”®å
        verify_keys = ['verify_1_point_opening', 'verify_5_equality', 'verify_7_orthogonality',
                      'verify_9_range', 'verify_16_aggregated']
        n_values = sorted([int(k) for k in data[verify_keys[0]].keys()])
        colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6A994E']

        for (name, color) in zip(verify_keys, colors):
            times = [data[name][str(n)] * 1000 for n in n_values]
            ax.plot(n_values, times, 'o-', linewidth=2, markersize=8, label=name, color=color)

        ax.set_xlabel('Vector Size (n)', fontsize=12, fontweight='bold')
        ax.set_ylabel('Time (ms)', fontsize=12, fontweight='bold')
        ax.set_title('Verification Performance Comparison', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=10)

        plt.tight_layout()
        plt.savefig('perf_verification.png', dpi=300, bbox_inches='tight')
        print("âœ… å·²ä¿å­˜: perf_verification.png")
        plt.close()
    
    def plot_memory_usage(self):
        """ç»˜åˆ¶å†…å­˜ä½¿ç”¨"""
        print("ğŸ“Š ç»˜åˆ¶å†…å­˜ä½¿ç”¨å›¾è¡¨...")
        
        data = self.memory_results.get('crs', {})
        if not data:
            print("âš ï¸  æ²¡æœ‰å†…å­˜æ•°æ®")
            return
        
        n_values = sorted([int(k) for k in data.keys()])
        memory = [data[str(n)] for n in n_values]
        
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.bar(range(len(n_values)), memory, color='#2E86AB', alpha=0.7, edgecolor='black', linewidth=1.5)
        ax.set_xticks(range(len(n_values)))
        ax.set_xticklabels([f'n={n}' for n in n_values])
        
        ax.set_xlabel('Vector Size (n)', fontsize=12, fontweight='bold')
        ax.set_ylabel('Memory Usage (MB)', fontsize=12, fontweight='bold')
        ax.set_title('CRS Memory Usage', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3, axis='y')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, v in enumerate(memory):
            ax.text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('perf_memory.png', dpi=300, bbox_inches='tight')
        print("âœ… å·²ä¿å­˜: perf_memory.png")
        plt.close()
    
    def plot_complexity_analysis(self):
        """ç»˜åˆ¶å¤æ‚åº¦åˆ†æ"""
        print("ğŸ“Š ç»˜åˆ¶å¤æ‚åº¦åˆ†æå›¾è¡¨...")
        
        data = self.timing_results.get('commitments', {})
        if not data:
            print("âš ï¸  æ²¡æœ‰æ•°æ®")
            return
        
        n_values = sorted([int(k) for k in data['commit_G'].keys()])
        times = [data['commit_G'][str(n)] * 1000 for n in n_values]
        
        # æ‹Ÿåˆ O(n) å’Œ O(n log n)
        fig, ax = plt.subplots(figsize=(12, 7))
        
        # å®é™…æ•°æ®
        ax.plot(n_values, times, 'o-', linewidth=2, markersize=8, label='Actual (commit_G)', color='#2E86AB')
        
        # ç†è®ºå¤æ‚åº¦
        if len(n_values) >= 2:
            # è®¡ç®— O(n) çš„ç³»æ•°
            coeff_n = times[0] / n_values[0]
            linear = [coeff_n * n for n in n_values]
            ax.plot(n_values, linear, '--', linewidth=2, label='O(n) fit', color='#F18F01', alpha=0.7)
            
            # è®¡ç®— O(n log n) çš„ç³»æ•°
            coeff_nlogn = times[0] / (n_values[0] * np.log(n_values[0]))
            nlogn = [coeff_nlogn * n * np.log(n) for n in n_values]
            ax.plot(n_values, nlogn, ':', linewidth=2, label='O(n log n) fit', color='#C73E1D', alpha=0.7)
        
        ax.set_xlabel('Vector Size (n)', fontsize=12, fontweight='bold')
        ax.set_ylabel('Time (ms)', fontsize=12, fontweight='bold')
        ax.set_title('Complexity Analysis: Commitment Generation', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=11)
        
        plt.tight_layout()
        plt.savefig('perf_complexity.png', dpi=300, bbox_inches='tight')
        print("âœ… å·²ä¿å­˜: perf_complexity.png")
        plt.close()
    
    def plot_overall_summary(self):
        """ç»˜åˆ¶æ€»ä½“æ€§èƒ½æ€»ç»“"""
        print("ğŸ“Š ç»˜åˆ¶æ€»ä½“æ€§èƒ½æ€»ç»“å›¾è¡¨...")

        # è·å–æœ€å¤§å‘é‡å¤§å°çš„æ•°æ®
        data_commit = self.timing_results.get('commitments', {})
        data_proof = self.timing_results.get('proofs', {})
        data_verify = self.timing_results.get('verification', {})

        if not (data_commit and data_proof and data_verify):
            print("âš ï¸  æ•°æ®ä¸å®Œæ•´")
            return

        # è·å–æœ€å¤§ n å€¼
        max_n = max(
            max(int(k) for k in data_commit['commit_G'].keys()),
            max(int(k) for k in data_proof['point_open'].keys()),
            max(int(k) for k in data_verify['verify_1_point_opening'].keys())
        )

        # è·å–æœ€å¤§ n çš„æ•°æ®
        max_n_str = str(max_n)

        categories = ['Commit_G', 'Commit_Ghat', 'Commit_Cy', 'Point_Open', 'Agg_Open', 'Verify_1', 'Verify_5']
        times = [
            data_commit['commit_G'][max_n_str] * 1000,
            data_commit['commit_Ghat'][max_n_str] * 1000,
            data_commit['commit_Cy'][max_n_str] * 1000,
            data_proof['point_open'][max_n_str] * 1000,
            data_proof['agg_open'][max_n_str] * 1000,
            data_verify['verify_1_point_opening'][max_n_str] * 1000,
            data_verify['verify_5_equality'][max_n_str] * 1000,
        ]

        fig, ax = plt.subplots(figsize=(14, 7))
        colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6A994E', '#D62828', '#F77F00']
        bars = ax.barh(categories, times, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)

        ax.set_xlabel('Time (ms)', fontsize=12, fontweight='bold')
        ax.set_title(f'Overall Performance Summary (n={max_n})', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3, axis='x')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, time) in enumerate(zip(bars, times)):
            ax.text(time + 0.1, i, f'{time:.2f}ms', va='center', fontweight='bold')

        plt.tight_layout()
        plt.savefig('perf_summary.png', dpi=300, bbox_inches='tight')
        print("âœ… å·²ä¿å­˜: perf_summary.png")
        plt.close()
    def plot_bandwidth_analysis(self):
            """ç»˜åˆ¶é€šä¿¡å¸¦å®½/å¼€é”€åˆ†æ"""
            print("ğŸ“Š ç»˜åˆ¶é€šä¿¡å¸¦å®½/å¼€é”€åˆ†æå›¾è¡¨...")

            data = self.timing_results.get('bandwidth', {})
            if not data:
                print("âš ï¸  æ²¡æœ‰å¸¦å®½æ•°æ®")
                return

            # æå–æ•°æ®
            n_values = sorted([int(k) for k in data['header_size'].keys()])
            header_sizes = [data['header_size'][str(n)] for n in n_values]
            proof_sizes = [data['proof_size'][str(n)] for n in n_values]
            raw_data_sizes = [data['raw_data_size'][str(n)] for n in n_values]

            # åˆ›å»ºå›¾è¡¨
            fig, ax = plt.subplots(figsize=(12, 8))

            # ç»˜åˆ¶ä¸‰æ¡çº¿
            ax.plot(n_values, header_sizes, 'o-', linewidth=2.5, markersize=10,
                    label='Header Size (Commitment)', color='#2E86AB') # æ”¹ä¸ºè‹±æ–‡æ ‡ç­¾
            ax.plot(n_values, proof_sizes, 's-', linewidth=2.5, markersize=10,
                    label='Proof Size (VC Proof)', color='#A23B72')   # æ”¹ä¸ºè‹±æ–‡æ ‡ç­¾
            ax.plot(n_values, raw_data_sizes, '^-', linewidth=2.5, markersize=10,
                    label='Raw Data Size (Baseline)', color='#F18F01') # æ”¹ä¸ºè‹±æ–‡æ ‡ç­¾

            # è®¾ç½®å¯¹æ•°åæ ‡ï¼ˆYè½´ï¼‰
            ax.set_yscale('log')

            # è®¾ç½®æ ‡ç­¾å’Œæ ‡é¢˜ï¼ˆæ”¹ä¸ºè‹±æ–‡ï¼Œé¿å…ä¹±ç ï¼‰
            ax.set_xlabel('Vector Size (N)', fontsize=13, fontweight='bold')
            ax.set_ylabel('Bytes (Log Scale)', fontsize=13, fontweight='bold')
            ax.set_title('Communication Cost Analysis', fontsize=15, fontweight='bold', pad=20)

            # ç½‘æ ¼å’Œå›¾ä¾‹
            ax.grid(True, alpha=0.3, which='both', linestyle='--')
            ax.legend(fontsize=11, loc='upper left', framealpha=0.9)

            # æ·»åŠ æ³¨é‡Šè¯´æ˜ O(1) ç‰¹æ€§
            if len(n_values) >= 2:
                mid_idx = len(n_values) // 2
                # ä¿®æ”¹ç‚¹ï¼šå°†ç®­å¤´é¢œè‰²æ”¹ä¸ºé»‘è‰² ('black')ï¼Œé¿å…æ··æ·†
                ax.annotate('Constant Size O(1)', 
                            xy=(n_values[mid_idx], proof_sizes[mid_idx]),
                            xytext=(n_values[mid_idx] * 1.3, proof_sizes[mid_idx] * 5), #ç¨å¾®è°ƒé«˜ä¸€ç‚¹ä½ç½®
                            fontsize=10, fontweight='bold', color='black', # æ–‡å­—æ”¹é»‘è‰²
                            bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8, edgecolor='gray'),
                            arrowprops=dict(arrowstyle='->', color='black', lw=1.5)) # ç®­å¤´æ”¹é»‘è‰²

            plt.tight_layout()
            plt.savefig('perf_bandwidth.png', dpi=300, bbox_inches='tight')
            print("âœ… å·²ä¿å­˜: perf_bandwidth.png")
            plt.close()
    
    def generate_all_plots(self):
        """ç”Ÿæˆæ‰€æœ‰å›¾è¡¨"""
        print("\n" + "="*60)
        print("ğŸ¨ å¼€å§‹ç”Ÿæˆæ€§èƒ½åˆ†æå›¾è¡¨")
        print("="*60 + "\n")

        self.plot_crs_generation()
        self.plot_commitments_comparison()
        self.plot_proofs_comparison()
        self.plot_verification_comparison()
        self.plot_memory_usage()
        self.plot_complexity_analysis()
        self.plot_overall_summary()
        self.plot_bandwidth_analysis()

        print("\n" + "="*60)
        print("âœ… æ‰€æœ‰å›¾è¡¨å·²ç”Ÿæˆ")
        print("="*60)


if __name__ == '__main__':
    analyzer = PerformanceAnalyzer()
    analyzer.generate_all_plots()

